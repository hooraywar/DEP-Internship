{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 285s 2us/step\n"
     ]
    }
   ],
   "source": [
    "# just checking the number of images in data \n",
    "dataset=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spliting the dataset into train and test and validation\n",
    "#(X_train, y_test), (y_train,  X_test) =cifar10.load_data()\n",
    "\n",
    "#(X_train, X_test), (y_train,y_test) =cifar10.load_data()\n",
    "(X_train , y_train), (X_test,y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train values (50000, 32, 32, 3)\n",
      "y_train values (50000, 1)\n",
      "X_test values (10000, 32, 32, 3)\n",
      "y_test values (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train values',X_train.shape)\n",
    "print('y_train values',y_train.shape)\n",
    "print('X_test values',X_test.shape)\n",
    "print('y_test values',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [8],\n",
       "       [0],\n",
       "       [6]], dtype=uint8)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       [[[ 28,  25,  10],\n",
       "         [ 37,  34,  19],\n",
       "         [ 38,  35,  20],\n",
       "         ...,\n",
       "         [ 76,  67,  39],\n",
       "         [ 81,  72,  43],\n",
       "         [ 85,  76,  47]],\n",
       "\n",
       "        [[ 33,  28,  13],\n",
       "         [ 34,  30,  14],\n",
       "         [ 32,  27,  12],\n",
       "         ...,\n",
       "         [ 95,  82,  55],\n",
       "         [ 96,  82,  56],\n",
       "         [ 85,  72,  45]],\n",
       "\n",
       "        [[ 39,  32,  15],\n",
       "         [ 40,  33,  17],\n",
       "         [ 57,  50,  33],\n",
       "         ...,\n",
       "         [ 93,  76,  52],\n",
       "         [107,  89,  66],\n",
       "         [ 95,  77,  54]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 83,  73,  52],\n",
       "         [ 87,  77,  56],\n",
       "         [ 84,  74,  52],\n",
       "         ...,\n",
       "         [ 99,  93,  70],\n",
       "         [ 90,  84,  61],\n",
       "         [ 81,  75,  52]],\n",
       "\n",
       "        [[ 88,  72,  51],\n",
       "         [ 90,  74,  52],\n",
       "         [ 93,  77,  56],\n",
       "         ...,\n",
       "         [ 80,  74,  53],\n",
       "         [ 76,  70,  49],\n",
       "         [ 82,  76,  55]],\n",
       "\n",
       "        [[ 97,  78,  56],\n",
       "         [ 94,  75,  53],\n",
       "         [ 93,  75,  53],\n",
       "         ...,\n",
       "         [ 54,  47,  28],\n",
       "         [ 63,  56,  37],\n",
       "         [ 72,  65,  46]]],\n",
       "\n",
       "\n",
       "       [[[170, 180, 198],\n",
       "         [168, 178, 196],\n",
       "         [177, 185, 203],\n",
       "         ...,\n",
       "         [162, 179, 215],\n",
       "         [158, 178, 214],\n",
       "         [157, 177, 212]],\n",
       "\n",
       "        [[168, 181, 198],\n",
       "         [172, 185, 201],\n",
       "         [171, 183, 200],\n",
       "         ...,\n",
       "         [159, 177, 212],\n",
       "         [156, 176, 211],\n",
       "         [154, 174, 209]],\n",
       "\n",
       "        [[154, 170, 186],\n",
       "         [149, 165, 181],\n",
       "         [129, 144, 162],\n",
       "         ...,\n",
       "         [161, 178, 214],\n",
       "         [157, 177, 212],\n",
       "         [154, 174, 209]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 74,  84,  80],\n",
       "         [ 76,  85,  81],\n",
       "         [ 78,  85,  82],\n",
       "         ...,\n",
       "         [ 71,  75,  78],\n",
       "         [ 68,  72,  75],\n",
       "         [ 61,  65,  68]],\n",
       "\n",
       "        [[ 68,  76,  77],\n",
       "         [ 69,  77,  78],\n",
       "         [ 72,  79,  78],\n",
       "         ...,\n",
       "         [ 76,  80,  83],\n",
       "         [ 71,  75,  78],\n",
       "         [ 71,  75,  78]],\n",
       "\n",
       "        [[ 67,  75,  78],\n",
       "         [ 68,  76,  79],\n",
       "         [ 69,  75,  76],\n",
       "         ...,\n",
       "         [ 75,  79,  82],\n",
       "         [ 71,  75,  78],\n",
       "         [ 73,  77,  80]]]], dtype=uint8)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[158, 112,  49],\n",
       "         [159, 111,  47],\n",
       "         [165, 116,  51],\n",
       "         ...,\n",
       "         [137,  95,  36],\n",
       "         [126,  91,  36],\n",
       "         [116,  85,  33]],\n",
       "\n",
       "        [[152, 112,  51],\n",
       "         [151, 110,  40],\n",
       "         [159, 114,  45],\n",
       "         ...,\n",
       "         [136,  95,  31],\n",
       "         [125,  91,  32],\n",
       "         [119,  88,  34]],\n",
       "\n",
       "        [[151, 110,  47],\n",
       "         [151, 109,  33],\n",
       "         [158, 111,  36],\n",
       "         ...,\n",
       "         [139,  98,  34],\n",
       "         [130,  95,  34],\n",
       "         [120,  89,  33]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 68, 124, 177],\n",
       "         [ 42, 100, 148],\n",
       "         [ 31,  88, 137],\n",
       "         ...,\n",
       "         [ 38,  97, 146],\n",
       "         [ 13,  64, 108],\n",
       "         [ 40,  85, 127]],\n",
       "\n",
       "        [[ 61, 116, 168],\n",
       "         [ 49, 102, 148],\n",
       "         [ 35,  85, 132],\n",
       "         ...,\n",
       "         [ 26,  82, 130],\n",
       "         [ 29,  82, 126],\n",
       "         [ 20,  64, 107]],\n",
       "\n",
       "        [[ 54, 107, 160],\n",
       "         [ 56, 105, 149],\n",
       "         [ 45,  89, 132],\n",
       "         ...,\n",
       "         [ 24,  77, 124],\n",
       "         [ 34,  84, 129],\n",
       "         [ 21,  67, 110]]],\n",
       "\n",
       "\n",
       "       [[[235, 235, 235],\n",
       "         [231, 231, 231],\n",
       "         [232, 232, 232],\n",
       "         ...,\n",
       "         [233, 233, 233],\n",
       "         [233, 233, 233],\n",
       "         [232, 232, 232]],\n",
       "\n",
       "        [[238, 238, 238],\n",
       "         [235, 235, 235],\n",
       "         [235, 235, 235],\n",
       "         ...,\n",
       "         [236, 236, 236],\n",
       "         [236, 236, 236],\n",
       "         [235, 235, 235]],\n",
       "\n",
       "        [[237, 237, 237],\n",
       "         [234, 234, 234],\n",
       "         [234, 234, 234],\n",
       "         ...,\n",
       "         [235, 235, 235],\n",
       "         [235, 235, 235],\n",
       "         [234, 234, 234]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 87,  99,  89],\n",
       "         [ 43,  51,  37],\n",
       "         [ 19,  23,  11],\n",
       "         ...,\n",
       "         [169, 184, 179],\n",
       "         [182, 197, 193],\n",
       "         [188, 202, 201]],\n",
       "\n",
       "        [[ 82,  96,  82],\n",
       "         [ 46,  57,  36],\n",
       "         [ 36,  44,  22],\n",
       "         ...,\n",
       "         [174, 189, 183],\n",
       "         [185, 200, 196],\n",
       "         [187, 202, 200]],\n",
       "\n",
       "        [[ 85, 101,  83],\n",
       "         [ 62,  75,  48],\n",
       "         [ 58,  67,  38],\n",
       "         ...,\n",
       "         [168, 183, 178],\n",
       "         [180, 195, 191],\n",
       "         [186, 200, 199]]],\n",
       "\n",
       "\n",
       "       [[[158, 190, 222],\n",
       "         [158, 187, 218],\n",
       "         [139, 166, 194],\n",
       "         ...,\n",
       "         [228, 231, 234],\n",
       "         [237, 239, 243],\n",
       "         [238, 241, 246]],\n",
       "\n",
       "        [[170, 200, 229],\n",
       "         [172, 199, 226],\n",
       "         [151, 176, 201],\n",
       "         ...,\n",
       "         [232, 232, 236],\n",
       "         [246, 246, 250],\n",
       "         [246, 247, 251]],\n",
       "\n",
       "        [[174, 201, 225],\n",
       "         [176, 200, 222],\n",
       "         [157, 179, 199],\n",
       "         ...,\n",
       "         [230, 229, 232],\n",
       "         [250, 249, 251],\n",
       "         [245, 244, 247]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 31,  40,  45],\n",
       "         [ 30,  39,  44],\n",
       "         [ 26,  35,  40],\n",
       "         ...,\n",
       "         [ 37,  40,  46],\n",
       "         [  9,  13,  14],\n",
       "         [  4,   7,   5]],\n",
       "\n",
       "        [[ 23,  34,  39],\n",
       "         [ 27,  38,  43],\n",
       "         [ 25,  36,  41],\n",
       "         ...,\n",
       "         [ 19,  20,  24],\n",
       "         [  4,   6,   3],\n",
       "         [  5,   7,   3]],\n",
       "\n",
       "        [[ 28,  41,  47],\n",
       "         [ 30,  43,  50],\n",
       "         [ 32,  45,  52],\n",
       "         ...,\n",
       "         [  5,   6,   8],\n",
       "         [  4,   5,   3],\n",
       "         [  7,   8,   7]]],\n",
       "\n",
       "\n",
       "       [[[155, 156, 149],\n",
       "         [167, 176, 187],\n",
       "         [176, 179, 193],\n",
       "         ...,\n",
       "         [201, 196, 209],\n",
       "         [202, 202, 212],\n",
       "         [192, 183, 171]],\n",
       "\n",
       "        [[153, 155, 157],\n",
       "         [163, 179, 204],\n",
       "         [171, 184, 215],\n",
       "         ...,\n",
       "         [202, 208, 222],\n",
       "         [203, 215, 227],\n",
       "         [189, 190, 183]],\n",
       "\n",
       "        [[155, 154, 153],\n",
       "         [160, 178, 201],\n",
       "         [168, 185, 213],\n",
       "         ...,\n",
       "         [206, 208, 215],\n",
       "         [204, 215, 224],\n",
       "         [189, 191, 184]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 89,  79,  62],\n",
       "         [ 57,  53,  52],\n",
       "         [ 61,  61,  59],\n",
       "         ...,\n",
       "         [ 89, 119, 101],\n",
       "         [ 59,  79,  62],\n",
       "         [ 67,  74,  50]],\n",
       "\n",
       "        [[ 89,  82,  62],\n",
       "         [ 60,  58,  53],\n",
       "         [ 63,  66,  58],\n",
       "         ...,\n",
       "         [ 57,  66,  58],\n",
       "         [ 61,  64,  54],\n",
       "         [ 75,  69,  51]],\n",
       "\n",
       "        [[ 92,  78,  64],\n",
       "         [ 60,  52,  51],\n",
       "         [ 61,  58,  51],\n",
       "         ...,\n",
       "         [ 60,  63,  50],\n",
       "         [ 64,  65,  52],\n",
       "         [ 73,  68,  50]]],\n",
       "\n",
       "\n",
       "       [[[ 65,  68,  50],\n",
       "         [ 70,  81,  64],\n",
       "         [ 48,  64,  46],\n",
       "         ...,\n",
       "         [ 51,  67,  41],\n",
       "         [ 54,  76,  53],\n",
       "         [ 67,  87,  66]],\n",
       "\n",
       "        [[ 69,  80,  58],\n",
       "         [ 79, 102,  81],\n",
       "         [ 60,  74,  57],\n",
       "         ...,\n",
       "         [ 54,  66,  44],\n",
       "         [ 65,  90,  69],\n",
       "         [ 61,  81,  66]],\n",
       "\n",
       "        [[ 73,  95,  72],\n",
       "         [ 84, 109,  87],\n",
       "         [ 72,  88,  70],\n",
       "         ...,\n",
       "         [ 78,  98,  75],\n",
       "         [ 73,  98,  77],\n",
       "         [ 48,  59,  51]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 95, 127,  92],\n",
       "         [ 91, 123,  86],\n",
       "         [ 57,  79,  45],\n",
       "         ...,\n",
       "         [144, 172, 108],\n",
       "         [170, 201, 134],\n",
       "         [122, 143,  98]],\n",
       "\n",
       "        [[ 94, 125,  82],\n",
       "         [ 75, 104,  71],\n",
       "         [ 32,  52,  24],\n",
       "         ...,\n",
       "         [143, 181, 116],\n",
       "         [154, 188, 123],\n",
       "         [106, 129,  89]],\n",
       "\n",
       "        [[ 78, 102,  65],\n",
       "         [ 35,  51,  27],\n",
       "         [ 24,  40,  17],\n",
       "         ...,\n",
       "         [143, 179, 136],\n",
       "         [154, 185, 146],\n",
       "         [128, 156, 117]]]], dtype=uint8)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped X_test [158 112  49 159 111]\n",
      "reshaped y_test [3 8 8 0 6]\n"
     ]
    }
   ],
   "source": [
    "#reshaping X_test and y_test\n",
    "\n",
    "X_test=X_test.reshape(-2,)\n",
    "y_test=y_test.reshape(-2,)\n",
    "print('reshaped X_test',X_test[:5])\n",
    "print('reshaped y_test',y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n",
      "automobile\n",
      "bird\n",
      "cat\n",
      "deer\n",
      "dog\n",
      "frog\n",
      "horse\n",
      "ship\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "for value in values:\n",
    " print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61960784 0.43921569 0.19215686 ... 0.10588235 0.10196078 0.10196078]\n"
     ]
    }
   ],
   "source": [
    "X_test=X_test/255.0\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.23137255 0.24313725 0.24705882]\n",
      "   [0.16862745 0.18039216 0.17647059]\n",
      "   [0.19607843 0.18823529 0.16862745]\n",
      "   ...\n",
      "   [0.61960784 0.51764706 0.42352941]\n",
      "   [0.59607843 0.49019608 0.4       ]\n",
      "   [0.58039216 0.48627451 0.40392157]]\n",
      "\n",
      "  [[0.0627451  0.07843137 0.07843137]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.07058824 0.03137255 0.        ]\n",
      "   ...\n",
      "   [0.48235294 0.34509804 0.21568627]\n",
      "   [0.46666667 0.3254902  0.19607843]\n",
      "   [0.47843137 0.34117647 0.22352941]]\n",
      "\n",
      "  [[0.09803922 0.09411765 0.08235294]\n",
      "   [0.0627451  0.02745098 0.        ]\n",
      "   [0.19215686 0.10588235 0.03137255]\n",
      "   ...\n",
      "   [0.4627451  0.32941176 0.19607843]\n",
      "   [0.47058824 0.32941176 0.19607843]\n",
      "   [0.42745098 0.28627451 0.16470588]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.81568627 0.66666667 0.37647059]\n",
      "   [0.78823529 0.6        0.13333333]\n",
      "   [0.77647059 0.63137255 0.10196078]\n",
      "   ...\n",
      "   [0.62745098 0.52156863 0.2745098 ]\n",
      "   [0.21960784 0.12156863 0.02745098]\n",
      "   [0.20784314 0.13333333 0.07843137]]\n",
      "\n",
      "  [[0.70588235 0.54509804 0.37647059]\n",
      "   [0.67843137 0.48235294 0.16470588]\n",
      "   [0.72941176 0.56470588 0.11764706]\n",
      "   ...\n",
      "   [0.72156863 0.58039216 0.36862745]\n",
      "   [0.38039216 0.24313725 0.13333333]\n",
      "   [0.3254902  0.20784314 0.13333333]]\n",
      "\n",
      "  [[0.69411765 0.56470588 0.45490196]\n",
      "   [0.65882353 0.50588235 0.36862745]\n",
      "   [0.70196078 0.55686275 0.34117647]\n",
      "   ...\n",
      "   [0.84705882 0.72156863 0.54901961]\n",
      "   [0.59215686 0.4627451  0.32941176]\n",
      "   [0.48235294 0.36078431 0.28235294]]]\n",
      "\n",
      "\n",
      " [[[0.60392157 0.69411765 0.73333333]\n",
      "   [0.49411765 0.5372549  0.53333333]\n",
      "   [0.41176471 0.40784314 0.37254902]\n",
      "   ...\n",
      "   [0.35686275 0.37254902 0.27843137]\n",
      "   [0.34117647 0.35294118 0.27843137]\n",
      "   [0.30980392 0.31764706 0.2745098 ]]\n",
      "\n",
      "  [[0.54901961 0.62745098 0.6627451 ]\n",
      "   [0.56862745 0.6        0.60392157]\n",
      "   [0.49019608 0.49019608 0.4627451 ]\n",
      "   ...\n",
      "   [0.37647059 0.38823529 0.30588235]\n",
      "   [0.30196078 0.31372549 0.24313725]\n",
      "   [0.27843137 0.28627451 0.23921569]]\n",
      "\n",
      "  [[0.54901961 0.60784314 0.64313725]\n",
      "   [0.54509804 0.57254902 0.58431373]\n",
      "   [0.45098039 0.45098039 0.43921569]\n",
      "   ...\n",
      "   [0.30980392 0.32156863 0.25098039]\n",
      "   [0.26666667 0.2745098  0.21568627]\n",
      "   [0.2627451  0.27058824 0.21568627]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.68627451 0.65490196 0.65098039]\n",
      "   [0.61176471 0.60392157 0.62745098]\n",
      "   [0.60392157 0.62745098 0.66666667]\n",
      "   ...\n",
      "   [0.16470588 0.13333333 0.14117647]\n",
      "   [0.23921569 0.20784314 0.22352941]\n",
      "   [0.36470588 0.3254902  0.35686275]]\n",
      "\n",
      "  [[0.64705882 0.60392157 0.50196078]\n",
      "   [0.61176471 0.59607843 0.50980392]\n",
      "   [0.62352941 0.63137255 0.55686275]\n",
      "   ...\n",
      "   [0.40392157 0.36470588 0.37647059]\n",
      "   [0.48235294 0.44705882 0.47058824]\n",
      "   [0.51372549 0.4745098  0.51372549]]\n",
      "\n",
      "  [[0.63921569 0.58039216 0.47058824]\n",
      "   [0.61960784 0.58039216 0.47843137]\n",
      "   [0.63921569 0.61176471 0.52156863]\n",
      "   ...\n",
      "   [0.56078431 0.52156863 0.54509804]\n",
      "   [0.56078431 0.5254902  0.55686275]\n",
      "   [0.56078431 0.52156863 0.56470588]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   ...\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.99215686 0.99215686 0.99215686]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   ...\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44313725 0.47058824 0.43921569]\n",
      "   [0.43529412 0.4627451  0.43529412]\n",
      "   [0.41176471 0.43921569 0.41568627]\n",
      "   ...\n",
      "   [0.28235294 0.31764706 0.31372549]\n",
      "   [0.28235294 0.31372549 0.30980392]\n",
      "   [0.28235294 0.31372549 0.30980392]]\n",
      "\n",
      "  [[0.43529412 0.4627451  0.43137255]\n",
      "   [0.40784314 0.43529412 0.40784314]\n",
      "   [0.38823529 0.41568627 0.38431373]\n",
      "   ...\n",
      "   [0.26666667 0.29411765 0.28627451]\n",
      "   [0.2745098  0.29803922 0.29411765]\n",
      "   [0.30588235 0.32941176 0.32156863]]\n",
      "\n",
      "  [[0.41568627 0.44313725 0.41176471]\n",
      "   [0.38823529 0.41568627 0.38431373]\n",
      "   [0.37254902 0.4        0.36862745]\n",
      "   ...\n",
      "   [0.30588235 0.33333333 0.3254902 ]\n",
      "   [0.30980392 0.33333333 0.3254902 ]\n",
      "   [0.31372549 0.3372549  0.32941176]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.1372549  0.69803922 0.92156863]\n",
      "   [0.15686275 0.69019608 0.9372549 ]\n",
      "   [0.16470588 0.69019608 0.94509804]\n",
      "   ...\n",
      "   [0.38823529 0.69411765 0.85882353]\n",
      "   [0.30980392 0.57647059 0.77254902]\n",
      "   [0.34901961 0.58039216 0.74117647]]\n",
      "\n",
      "  [[0.22352941 0.71372549 0.91764706]\n",
      "   [0.17254902 0.72156863 0.98039216]\n",
      "   [0.19607843 0.71764706 0.94117647]\n",
      "   ...\n",
      "   [0.61176471 0.71372549 0.78431373]\n",
      "   [0.55294118 0.69411765 0.80784314]\n",
      "   [0.45490196 0.58431373 0.68627451]]\n",
      "\n",
      "  [[0.38431373 0.77254902 0.92941176]\n",
      "   [0.25098039 0.74117647 0.98823529]\n",
      "   [0.27058824 0.75294118 0.96078431]\n",
      "   ...\n",
      "   [0.7372549  0.76470588 0.80784314]\n",
      "   [0.46666667 0.52941176 0.57647059]\n",
      "   [0.23921569 0.30980392 0.35294118]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28627451 0.30980392 0.30196078]\n",
      "   [0.20784314 0.24705882 0.26666667]\n",
      "   [0.21176471 0.26666667 0.31372549]\n",
      "   ...\n",
      "   [0.06666667 0.15686275 0.25098039]\n",
      "   [0.08235294 0.14117647 0.2       ]\n",
      "   [0.12941176 0.18823529 0.19215686]]\n",
      "\n",
      "  [[0.23921569 0.26666667 0.29411765]\n",
      "   [0.21568627 0.2745098  0.3372549 ]\n",
      "   [0.22352941 0.30980392 0.40392157]\n",
      "   ...\n",
      "   [0.09411765 0.18823529 0.28235294]\n",
      "   [0.06666667 0.1372549  0.20784314]\n",
      "   [0.02745098 0.09019608 0.1254902 ]]\n",
      "\n",
      "  [[0.17254902 0.21960784 0.28627451]\n",
      "   [0.18039216 0.25882353 0.34509804]\n",
      "   [0.19215686 0.30196078 0.41176471]\n",
      "   ...\n",
      "   [0.10588235 0.20392157 0.30196078]\n",
      "   [0.08235294 0.16862745 0.25882353]\n",
      "   [0.04705882 0.12156863 0.19607843]]]\n",
      "\n",
      "\n",
      " [[[0.74117647 0.82745098 0.94117647]\n",
      "   [0.72941176 0.81568627 0.9254902 ]\n",
      "   [0.7254902  0.81176471 0.92156863]\n",
      "   ...\n",
      "   [0.68627451 0.76470588 0.87843137]\n",
      "   [0.6745098  0.76078431 0.87058824]\n",
      "   [0.6627451  0.76078431 0.8627451 ]]\n",
      "\n",
      "  [[0.76078431 0.82352941 0.9372549 ]\n",
      "   [0.74901961 0.81176471 0.9254902 ]\n",
      "   [0.74509804 0.80784314 0.92156863]\n",
      "   ...\n",
      "   [0.67843137 0.75294118 0.8627451 ]\n",
      "   [0.67058824 0.74901961 0.85490196]\n",
      "   [0.65490196 0.74509804 0.84705882]]\n",
      "\n",
      "  [[0.81568627 0.85882353 0.95686275]\n",
      "   [0.80392157 0.84705882 0.94117647]\n",
      "   [0.8        0.84313725 0.9372549 ]\n",
      "   ...\n",
      "   [0.68627451 0.74901961 0.85098039]\n",
      "   [0.6745098  0.74509804 0.84705882]\n",
      "   [0.6627451  0.74901961 0.84313725]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.81176471 0.78039216 0.70980392]\n",
      "   [0.79607843 0.76470588 0.68627451]\n",
      "   [0.79607843 0.76862745 0.67843137]\n",
      "   ...\n",
      "   [0.52941176 0.51764706 0.49803922]\n",
      "   [0.63529412 0.61960784 0.58823529]\n",
      "   [0.65882353 0.63921569 0.59215686]]\n",
      "\n",
      "  [[0.77647059 0.74509804 0.66666667]\n",
      "   [0.74117647 0.70980392 0.62352941]\n",
      "   [0.70588235 0.6745098  0.57647059]\n",
      "   ...\n",
      "   [0.69803922 0.67058824 0.62745098]\n",
      "   [0.68627451 0.6627451  0.61176471]\n",
      "   [0.68627451 0.6627451  0.60392157]]\n",
      "\n",
      "  [[0.77647059 0.74117647 0.67843137]\n",
      "   [0.74117647 0.70980392 0.63529412]\n",
      "   [0.69803922 0.66666667 0.58431373]\n",
      "   ...\n",
      "   [0.76470588 0.72156863 0.6627451 ]\n",
      "   [0.76862745 0.74117647 0.67058824]\n",
      "   [0.76470588 0.74509804 0.67058824]]]\n",
      "\n",
      "\n",
      " [[[0.89803922 0.89803922 0.9372549 ]\n",
      "   [0.9254902  0.92941176 0.96862745]\n",
      "   [0.91764706 0.9254902  0.96862745]\n",
      "   ...\n",
      "   [0.85098039 0.85882353 0.91372549]\n",
      "   [0.86666667 0.8745098  0.91764706]\n",
      "   [0.87058824 0.8745098  0.91372549]]\n",
      "\n",
      "  [[0.87058824 0.86666667 0.89803922]\n",
      "   [0.9372549  0.9372549  0.97647059]\n",
      "   [0.91372549 0.91764706 0.96470588]\n",
      "   ...\n",
      "   [0.8745098  0.8745098  0.9254902 ]\n",
      "   [0.89019608 0.89411765 0.93333333]\n",
      "   [0.82352941 0.82745098 0.8627451 ]]\n",
      "\n",
      "  [[0.83529412 0.80784314 0.82745098]\n",
      "   [0.91764706 0.90980392 0.9372549 ]\n",
      "   [0.90588235 0.91372549 0.95686275]\n",
      "   ...\n",
      "   [0.8627451  0.8627451  0.90980392]\n",
      "   [0.8627451  0.85882353 0.90980392]\n",
      "   [0.79215686 0.79607843 0.84313725]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.58823529 0.56078431 0.52941176]\n",
      "   [0.54901961 0.52941176 0.49803922]\n",
      "   [0.51764706 0.49803922 0.47058824]\n",
      "   ...\n",
      "   [0.87843137 0.87058824 0.85490196]\n",
      "   [0.90196078 0.89411765 0.88235294]\n",
      "   [0.94509804 0.94509804 0.93333333]]\n",
      "\n",
      "  [[0.5372549  0.51764706 0.49411765]\n",
      "   [0.50980392 0.49803922 0.47058824]\n",
      "   [0.49019608 0.4745098  0.45098039]\n",
      "   ...\n",
      "   [0.70980392 0.70588235 0.69803922]\n",
      "   [0.79215686 0.78823529 0.77647059]\n",
      "   [0.83137255 0.82745098 0.81176471]]\n",
      "\n",
      "  [[0.47843137 0.46666667 0.44705882]\n",
      "   [0.4627451  0.45490196 0.43137255]\n",
      "   [0.47058824 0.45490196 0.43529412]\n",
      "   ...\n",
      "   [0.70196078 0.69411765 0.67843137]\n",
      "   [0.64313725 0.64313725 0.63529412]\n",
      "   [0.63921569 0.63921569 0.63137255]]]]\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train/255.0\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_en = to_categorical(y_train, 10)\n",
    "y_test_en = to_categorical(y_test, 10)\n",
    "print(y_test_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(32,32,3)))\n",
    "model_cnn.add(MaxPooling2D(pool_size=2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(10, activation='relu'))\n",
    "model_cnn.add(Dense(1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10, 10) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[244], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model_cnn\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#CNN = model_cnn.fit(X_train, X_test, epochs=5, batch_size=32, validation_data=(y_train, y_test))\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m CNN \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m loss_cnn, accuracy_cnn \u001b[38;5;241m=\u001b[39m model_cnn\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test_en)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss (CNN): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_cnn\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32me:\\software\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileu13apa05.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"e:\\software\\Lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10, 10) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "#CNN = model_cnn.fit(X_train, X_test, epochs=5, batch_size=32, validation_data=(y_train, y_test))\n",
    "CNN = model_cnn.fit(X_train, y_train_en, epochs=5)\n",
    "\n",
    "loss_cnn, accuracy_cnn = model_cnn.evaluate(X_test, y_test_en)\n",
    "print(f'Test Loss (CNN): {loss_cnn:.4f}')\n",
    "print(f'Test Accuracy (CNN): {accuracy_cnn * 100:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
